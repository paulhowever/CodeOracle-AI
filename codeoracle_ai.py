# -*- coding: utf-8 -*-
"""CodeOracle AI

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14CYMZ1B8V3dpU_oVd-kRrI_F3H3ufvdj
"""

pip install chromadb

import pandas as pd
from sentence_transformers import SentenceTransformer
import chromadb
from typing import List, Dict, Any
import google.generativeai as genai
import os

# Загрузка данных
questions = pd.read_csv("Questions.csv", encoding='latin1')
answers = pd.read_csv("Answers.csv", encoding='latin1')
tags = pd.read_csv("Tags.csv", encoding='latin1')



# Объединение вопросов с тегами
questions_with_tags = pd.merge(questions, tags, how='left', on='Id')

answers

import nltk

nltk.download('stopwords')


nltk.download('wordnet')  # для лемматизации
nltk.download('omw-1.4')   # Мультиязычный WordNet

import re
from bs4 import BeautifulSoup
from nltk.stem import WordNetLemmatizer
from nltk.corpus import stopwords

def clean_text(text):
    # удаляем хтмл и маркдауны
    text = BeautifulSoup(text, 'html.parser').get_text()
    # делит код
    text = re.sub(r'<code>.*?</code>', '', text, flags=re.DOTALL)
    # Удаление спецсимволов и приведение к нижнему регистру
    text = re.sub(r'[^a-zA-Z\s]', '', text).lower()
    # удаление стоп-слов
    stop_words = set(stopwords.words('english'))
    words = [word for word in text.split() if word not in stop_words]
    # лемматизируем йоуууууу
    lemmatizer = WordNetLemmatizer()
    words = [lemmatizer.lemmatize(word) for word in words]
    return ' '.join(words)

# фигачим очищаем все вопросы и ответы
questions['CleanBody'] = questions['Body'].apply(clean_text)
answers['CleanBody'] = answers['Body'].apply(clean_text)

# объединение вопросов с ответами
qa_data = pd.merge(questions, answers, how='left', left_on='Id', right_on='ParentId')
qa_data = qa_data.drop_duplicates(subset=['Id_y'])

# объединение вопросов с ответами
print(f"Размер данных до объединения: {len(questions)} вопросов, {len(answers)} ответов")

qa_data = pd.merge(questions, answers, how='left', left_on='Id', right_on='ParentId')
print(f"Размер после объединения (до удаления дубликатов): {len(qa_data)} строк")

initial_count = len(qa_data)
qa_data = qa_data.drop_duplicates(subset=['Id_y'])
removed_count = initial_count - len(qa_data)

print(f"Удалено дубликатов: {removed_count} строк")
print(f"Итоговый размер данных: {len(qa_data)} строк")

# проверка наличия необходимых колонок
print("\nПроверка колонок в итоговом DataFrame:")
print(qa_data.columns.tolist())

df = pd.DataFrame(qa_data)

# сохраняем в CSV с UTF-8
df.to_csv("qa_data.csv", index=False, encoding="utf-8")

import matplotlib.pyplot as plt
import seaborn as sns

# мейн хар-ки дфа
def basic_statistics(questions, answers):
    print("мейн хар-ки ")

    # колво
    total_questions = questions['Id'].nunique()
    total_answers = answers['Id'].nunique()
    print(f"Всего вопросов: {total_questions:,}")
    print(f"Всего ответов: {total_answers:,}")

    # ср-е значения
    answers_per_question = answers.groupby('ParentId').size().mean()
    print(f"Среднее количество ответов на вопрос: {answers_per_question:.2f}")

    avg_question_score = questions['Score'].mean()
    avg_answer_score = answers['Score'].mean()
    print(f"Средний рейтинг вопросов: {avg_question_score:.2f}")
    print(f"Средний рейтинг ответов: {avg_answer_score:.2f}")

    # еще приколы
    median_question_score = questions['Score'].median()
    median_answer_score = answers['Score'].median()
    print(f"\nМедианный рейтинг вопросов: {median_question_score}")
    print(f"Медианный рейтинг ответов: {median_answer_score}")

    # Кколво вопросов без ответов
    unanswered = total_questions - answers['ParentId'].nunique()
    print(f"\nВопросов без ответов: {unanswered:,} ({unanswered/total_questions*100:.1f}%)")

# теги
def analyze_tags(tags):
    print("\n теги")

    # топ 10
    top_tags = tags['Tag'].value_counts().head(10)
    print("\nТоп-10 популярных тегов:")
    print(top_tags.to_string())

    # всякие приколы
    tags_per_question = tags.groupby('Id').size()
    print(f"\nСреднее количество тегов на вопрос: {tags_per_question.mean():.2f}")
    print(f"Максимальное количество тегов у одного вопроса: {tags_per_question.max()}")

# длина и ее анализ
def analyze_text_length(questions, answers):
    print("\n len текста")

    # добавляем столбцы с длиной текста
    questions['BodyLength'] = questions['Body'].str.len()
    answers['BodyLength'] = answers['Body'].str.len()

    # мейн стата
    print(f"Средняя длина вопроса: {questions['BodyLength'].mean():.0f} символов")
    print(f"Медианная длина вопроса: {questions['BodyLength'].median():.0f} символов")
    print(f"\nСредняя длина ответа: {answers['BodyLength'].mean():.0f} символов")
    print(f"Медианная длина ответа: {answers['BodyLength'].median():.0f} символов")



# анализ рейта
def analyze_scores(questions, answers):

    # визуализация распределения рейтингов вопросов
    plt.figure(figsize=(12, 6))
    plt.subplot(1, 2, 1)
    sns.boxplot(x=questions['Score'])
    plt.title('Распределение рейтингов вопросов')

    # визуализация распределения рейтингов ответов
    plt.subplot(1, 2, 2)
    sns.boxplot(x=answers['Score'])
    plt.title('Распределение рейтингов ответов')
    plt.tight_layout()
    plt.show()

    # корреляция между длиной и рейтингом
    plt.figure(figsize=(12, 6))
    sns.scatterplot(x=questions['BodyLength'], y=questions['Score'], alpha=0.3)
    plt.title('Зависимость рейтинга вопроса от его длины')
    plt.xlabel('Длина вопроса')
    plt.ylabel('Рейтинг')
    plt.show()


    # распределение рейтингов вопросов
    plt.figure(figsize=(10,6))
    sns.boxplot(x=questions['Score'])
    plt.title('Распределение рейтингов вопросов')
    plt.show()


basic_statistics(questions, answers)
analyze_tags(tags)
analyze_text_length(questions, answers)
analyze_scores(questions, answers)

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.ticker import MaxNLocator
import numpy as np


# подготовка данных
questions['BodyLength'] = questions['Body'].str.len()
tag_counts = tags['Tag'].value_counts().reset_index()
tag_counts.columns = ['Tag', 'Count']


# график распределения частоты тегов (топ-15)
plt.figure(figsize=(14, 8))
top_tags = tag_counts.head(15)

ax1 = sns.barplot(data=top_tags, y='Tag', x='Count',
                 edgecolor='black', linewidth=0.5)


# график распределения длины вопросов
plt.figure(figsize=(14, 6))

# гистограмма с KDE
ax2 = sns.histplot(data=questions, x='BodyLength',
                  bins=50, kde=True,
                  edgecolor='white', linewidth=0.5)

from wordcloud import WordCloud


# облачко крутое
tag_counts = tags['Tag'].value_counts()
wordcloud = WordCloud(width=800, height=400,
                      background_color='white',
                      colormap='viridis').generate_from_frequencies(tag_counts)

plt.figure(figsize=(15, 8))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Облако тегов StackOverflow', fontsize=16)
plt.show()

# анализ временных
questions['CreationDate'] = pd.to_datetime(questions['CreationDate'])
questions['Year'] = questions['CreationDate'].dt.year

plt.figure(figsize=(12, 6))
questions['Year'].value_counts().sort_index().plot(kind='bar', color='teal')
plt.title('Количество вопросов по годам', fontsize=14)
plt.xlabel('Год', fontsize=12)
plt.ylabel('Количество вопросов', fontsize=12)
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# категории тегов
categories = {
    'Языки программирования': [
        'javascript', 'python', 'java', 'c#', 'php', 'c++', 'c', 'typescript',
        'ruby', 'swift', 'go', 'rust', 'kotlin', 'scala', 'r', 'dart'
    ],
    'Веб-разработка': [
        'html', 'css', 'jquery', 'angular', 'reactjs', 'vue.js', 'django',
        'flask', 'spring', 'laravel', 'asp.net', 'node.js', 'express'
    ],
    'Мобильная разработка': [
        'android', 'ios', 'react-native', 'flutter', 'xamarin', 'ionic'
    ],
    'Базы данных': [
        'sql', 'mysql', 'postgresql', 'mongodb', 'oracle', 'sql-server',
        'sqlite', 'firebase'
    ],
    'DevOps и инструменты': [
        'docker', 'kubernetes', 'git', 'jenkins', 'aws', 'azure', 'linux',
        'bash', 'nginx'
    ],
    'Машинное обучение': [
        'machine-learning', 'tensorflow', 'pytorch', 'keras', 'neural-network',
        'deep-learning', 'nlp', 'scikit-learn'
    ]
}

# модификация для категории тегов
def categorize_tag(tag):
    if pd.isna(tag):  # проверяем на NaN
        return 'Другое'
    try:
        tag_lower = str(tag).lower()  # преобразуем в строку
        for category, tags_list in categories.items():
            if tag_lower in tags_list:
                return category
        return 'Другое'
    except:
        return 'Другое'

# 3. категаризируем
tags['Category'] = tags['Tag'].apply(categorize_tag)

# подсчет вопросов по тегам
category_counts = tags.groupby('Category')['Id'].count().sort_values(ascending=False)
category_percents = category_counts / category_counts.sum() * 100

# рисуем
plt.figure(figsize=(14, 10))

# гистограмма
ax1 = plt.subplot(2, 1, 1)
bars = sns.barplot(
    x=category_counts.index,
    y=category_counts.values,
    palette='viridis',
    edgecolor='black',
    linewidth=0.5
)

# Добавляем подписи значений
for bar in bars.patches:
    height = bar.get_height()
    ax1.text(bar.get_x() + bar.get_width()/2., height + 5,
            f'{int(height)}',
            ha='center', va='bottom')

plt.title('Распределение вопросов по категориям тегов', fontsize=16)
plt.ylabel('Количество вопросов', fontsize=12)
plt.xticks(rotation=45, ha='right')
plt.xlabel('')

# Ккруговая диаграмма
ax2 = plt.subplot(2, 1, 2)
plt.pie(
    category_counts,
    labels=category_counts.index,
    autopct='%1.1f%%',
    startangle=90,
    colors=sns.color_palette('viridis', len(category_counts)),
    wedgeprops={'edgecolor': 'black', 'linewidth': 0.5}
)
plt.axis('equal')
plt.title('Доля вопросов по категориям (%)', fontsize=16)

plt.tight_layout()
plt.show()

other_tags = tags[tags['Category'] == 'Другое']['Tag'].value_counts().head(20)
print(other_tags)

print(f"Пропущенных тегов: {tags['Tag'].isna().sum()}")

DB_PATH = "chroma_db"
COLLECTION_NAME = "StackOverflowQnA"
EMBEDDING_MODEL = 'all-MiniLM-L6-v2'
#GEMINI_API_KEY = "AIzaSyBiaWr3Vmd1WawMn7_5Alsp5cfHaqnKfKI"
GEMINI_API_KEY = "AIzaSyBbXCrPV1NgCItEsbCmnQhZ4FNUIHCejh0"

GEMINI_MODEL = "gemini-1.5-flash-latest"

# Инициализация Gemini
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel(GEMINI_MODEL)

def load_and_prepare_data(filepath: str, tags_filepath: str = "Tags.csv") -> pd.DataFrame:
    """Загрузка и подготовка данных с объединением тегов."""
    # Загрузка основного датасета
    dataset = pd.read_csv(filepath)

    # Загрузка тегов
    tags_df = pd.read_csv(tags_filepath)

    # Преобразуем все теги в строки и удаляем возможные NaN значения
    tags_df['Tag'] = tags_df['Tag'].astype(str)
    tags_df = tags_df[tags_df['Tag'] != 'nan']  # Удаляем строки с 'nan'

    # Группируем теги по Id (объединяем все теги для одного вопроса через запятую)
    tags_grouped = tags_df.groupby('Id')['Tag'].apply(
        lambda x: ', '.join(str(tag) for tag in x if pd.notna(tag) and str(tag) != 'nan')
    ).reset_index()

    # Мерджим с основным датасетом
    dataset = pd.merge(
        dataset,
        tags_grouped,
        left_on="Id_x",
        right_on="Id",
        how="left"
    )

    # Заполняем пропуски (если у вопроса нет тегов)
    dataset['Tag'] = dataset['Tag'].fillna('Python')

    # Создаем необходимые колонки
    dataset["id"] = dataset["Id_x"].astype(str)
    dataset["text"] = dataset["Title"] + " " + dataset["CleanBody_x"]

    return dataset

def generate_embeddings(dataset: pd.DataFrame) -> pd.DataFrame:
    """Генерация эмбеддингов для текста."""
    model = SentenceTransformer(EMBEDDING_MODEL)

    # 1. Заполняем пропуски и преобразуем всё в строки
    dataset["text"] = dataset["text"].fillna("").astype(str)

    # 2. Удаляем строки с пустым текстом (опционально)
    dataset = dataset[dataset["text"].str.strip() != ""]

    # 3. Генерируем эмбеддинги только для непустых текстов
    dataset["embedding"] = dataset["text"].apply(
        lambda x: model.encode(x).tolist() if x.strip() else None
    )

    # 4. Удаляем строки, где не удалось создать эмбеддинг
    dataset = dataset.dropna(subset=["embedding"])

    return dataset

def prepare_metadatas(dataset: pd.DataFrame) -> List[Dict[str, Any]]:
    """Подготовка метаданных для коллекции с использованием реальных тегов."""
    metadatas = []
    for _, row in dataset.iterrows():
        metadata = {
            "question": row["Title"],
            "answer": row["CleanBody_y"],
            "tags": row["Tag"],
            "score": row["Score_y"],
        }
        metadatas.append(metadata)
    return metadatas

def initialize_chroma_collection() -> chromadb.Collection:
    client = chromadb.PersistentClient(path=DB_PATH)

    # Получаем или создаем коллекцию
    collection = client.get_or_create_collection(COLLECTION_NAME)

    return collection
def semantic_search(query: str, collection: chromadb.Collection,
                   model: SentenceTransformer, top_k: int = 3) -> Dict:
    """Выполнение семантического поиска."""
    query_embedding = model.encode(query).tolist()
    results = collection.query(
        query_embeddings=[query_embedding],
        n_results=top_k
    )
    return results

def format_prompt(user_query: str, search_results: Dict) -> str:
    """Формирование промпта для LLM на основе результатов поиска."""
    context_parts = []

    for i, (metadata, distance) in enumerate(zip(search_results["metadatas"][0], search_results["distances"][0])):
        context_part = (
            f"Похожий вопрос {i+1}:\n"
            f"Вопрос: {metadata['question']}\n"
            f"Ответ: {metadata['answer'][:1000]}\n"
            f"Теги: {metadata['tags']}\n"
            f"Рейтинг: {metadata['score']}\n"
            f"Сходство: {distance:.4f}\n"
        )
        context_parts.append(context_part)

    context = "\n".join(context_parts)

    prompt = (
        "Ты - помощник по программированию, который отвечает на вопросы, используя информацию "
        "из базы знаний Stack Overflow. Вот контекст из базы знаний с похожими вопросами и ответами:\n\n"
        f"{context}\n\n"
        "Вопрос пользователя:\n"
        f"{user_query}\n\n"
        "Сформулируй развернутый ответ, используя информацию из контекста, если ее нет то напиши что ответа нету гони монету. "
    )

    return prompt

def generate_answer(prompt: str) -> str:
    """Генерация ответа с помощью Gemini API."""
    response = model.generate_content(prompt)
    return response.text

def rag_pipeline(user_query: str, collection: chromadb.Collection, embedding_model: SentenceTransformer) -> str:
    """Полный RAG пайплайн: поиск + генерация."""
    # 1. Выполняем семантический поиск
    search_results = semantic_search(user_query, collection, embedding_model)

    # 2. формируем промпт
    prompt = format_prompt(user_query, search_results)

    # 3. генерируем ответ
    answer = generate_answer(prompt)

    return answer

def main():
    # Загрузка и подготовка данных
    dataset = load_and_prepare_data("StackOverflow_QA.csv")

    # Генерация эмбеддингов
    embedding_model = SentenceTransformer(EMBEDDING_MODEL)
    dataset = generate_embeddings(dataset)

    # Подготовка метаданных
    metadatas = prepare_metadatas(dataset)

    # Инициализация ChromaDB
    collection = initialize_chroma_collection()

    # Добавление данных в коллекцию (если они еще не добавлены)
    if collection.count() == 0:
        collection.add(
            ids=dataset["id"].tolist(),
            embeddings=dataset["embedding"].tolist(),
            metadatas=metadatas
        )

    # Примеры вопросов для тестирования
    test_queries = [
        "How to convert the text Sunday March PM into a proper date value in Excel?",
        "using numpy following lnx equivalent nplogx apologise seemingly trivial question understanding difference log ln ln logspace e",
        "Как в Perl различаются лексическая и динамическая область видимости переменных, и какие операторы (my или local) используются для каждой из них?"
    ]

    # Тестируем RAG пайплайн
    for query in test_queries:
        print(f"\n{'='*50}\nВопрос: {query}\n{'='*50}")

        # Получаем ответ через RAG
        answer = rag_pipeline(query, collection, embedding_model)

        print(f"\nОтвет:\n{answer}\n")